import pandas as pd
import os
import json
import glob
from datetime import datetime
import sys

# Path settings
csv_file = "tasks.csv"
tasks_dir = "tasks"
csv_raw_dir = "csv/raw"
csv_cleaned_dir = "csv/cleaned"
backup_dir = "backup"

# ì—´ ì´ë¦„ ì •ì˜ (í—¤ë” ì—†ìŒ ê°€ì •)
CSV_COLUMNS = ['id', 'username', 'mainCategory', 'subCategory', 'startTime', 'elapsedTime', 'endTime', 'quantity', 'note']

def clean_csv():
    try:
        if not os.path.exists(csv_file):
            print("âš ï¸ CSV file not found.")
            return

        # CSV ì½ê¸° (í—¤ë” ì—†ìŒ, ì—´ ì´ë¦„ ì§€ì •)
        df = pd.read_csv(csv_file, header=None, names=CSV_COLUMNS, on_bad_lines='warn')
        if df.empty:
            print("âš ï¸ CSV is empty.")
            return

        # ë°±ì—…
        date_str = datetime.now().strftime('%Y-%m-%d')
        os.makedirs(backup_dir, exist_ok=True)
        backup_file = os.path.join(backup_dir, f"tasks_{date_str}.csv")
        df.to_csv(backup_file, index=False)
        print(f"âœ… CSV backup saved: {backup_file}")

        # ë‚ ì§œë³„ ë¶„ë¦¬
        os.makedirs(csv_raw_dir, exist_ok=True)
        os.makedirs(csv_cleaned_dir, exist_ok=True)
        
        # endTimeìœ¼ë¡œ ë‚ ì§œ ì¶”ì¶œ
        df['date'] = pd.to_datetime(df['endTime'], errors='coerce').dt.date
        if df['date'].isna().all():
            print("âš ï¸ All endTime values are invalid. Using current date as fallback.")
            df['date'] = datetime.now().date()

        for date, group in df.groupby('date'):
            if pd.isna(date):
                print(f"âš ï¸ Skipping invalid date group")
                continue
            
            # Raw ë²„ì „
            raw_file = os.path.join(csv_raw_dir, f"tasks_{date}.csv")
            if os.path.exists(raw_file):
                existing_raw_df = pd.read_csv(raw_file, header=None, names=CSV_COLUMNS, on_bad_lines='warn')
                combined_raw_df = pd.concat([existing_raw_df, group.drop(columns=['date'])])
            else:
                combined_raw_df = group.drop(columns=['date'])
            combined_raw_df.to_csv(raw_file, index=False, header=False)  # í—¤ë” ì—†ì´ ì €ì¥
            print(f"âœ… Raw CSV saved for {date}: {raw_file}")

            # Cleaned ë²„ì „
            cleaned_file = os.path.join(csv_cleaned_dir, f"tasks_{date}.csv")
            cleaned_df = group.drop_duplicates(subset=['id'], keep='last')
            if os.path.exists(cleaned_file):
                existing_cleaned_df = pd.read_csv(cleaned_file, header=None, names=CSV_COLUMNS, on_bad_lines='warn')
                combined_cleaned_df = pd.concat([existing_cleaned_df, cleaned_df.drop(columns=['date'])])
                combined_cleaned_df = combined_cleaned_df.drop_duplicates(subset=['id'], keep='last')
            else:
                combined_cleaned_df = cleaned_df.drop(columns=['date'])
            combined_cleaned_df.to_csv(cleaned_file, index=False, header=False)  # í—¤ë” ì—†ì´ ì €ì¥
            print(f"âœ… Cleaned CSV saved for {date}: {cleaned_file}")

    except Exception as e:
        print(f"âŒ Error cleaning CSV: {e}")
    finally:
        try:
            with open(csv_file, 'w') as f:
                f.truncate(0)
            print(f"âœ… CSV cleared: {csv_file}")
        except Exception as e:
            print(f"âŒ Error clearing tasks.csv: {e}")

def clean_json():
    try:
        json_files = glob.glob(os.path.join(tasks_dir, "*.json"))
        if not json_files:
            print("âš ï¸ No JSON files found.")
            return

        for json_file in json_files:
            print(f"ğŸ” Processing JSON file: {json_file}")
            with open(json_file, 'r', encoding='utf8') as f:
                tasks = json.load(f)
            print(f"ğŸ“‹ Original tasks count: {len(tasks)}")

            cleaned_tasks = [task for task in tasks if task.get('status', 'pending') != 'completed']
            print(f"ğŸ“‹ Cleaned tasks count: {len(cleaned_tasks)}")

            with open(json_file, 'w', encoding='utf8') as f:
                json.dump(cleaned_tasks, f, indent=2)
            print(f"âœ… JSON cleaned: {json_file} (remaining tasks: {len(cleaned_tasks)})")
    except Exception as e:
        print(f"âŒ Error cleaning JSON: {e}")

def main():
    if len(sys.argv) < 2:
        print("Usage: python clean_tracker.py [csv|json|all]")
        print("  - csv: Clean only CSV")
        print("  - json: Clean only JSON")
        print("  - all: Clean both CSV and JSON")
        return

    mode = sys.argv[1].lower()
    print(f"ğŸ” Starting tracker cleanup: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    if mode == 'csv':
        clean_csv()
    elif mode == 'json':
        clean_json()
    elif mode == 'all':
        clean_csv()
        clean_json()
    else:
        print(f"âŒ Invalid mode: {mode}. Use 'csv', 'json', or 'all'.")
        return

    print("âœ… Cleanup completed!")

if __name__ == "__main__":
    main()